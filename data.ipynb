{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Extração das imagens do .rec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.bool = np.bool_\n",
    "import mxnet as mx\n",
    "import cv2\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_path = './data/CASIA/faces_webface_112x112/'\n",
    "output_dir = './data/CASIA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import mxnet as mx\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_mx_rec(df, rec_path, save_path, write_img=True):\n",
    "    if write_img:\n",
    "        if not os.path.isdir(save_path + \"/casia-faces\"):\n",
    "            os.makedirs(save_path + \"/casia-faces\")\n",
    "\n",
    "    imgrec = mx.recordio.MXIndexedRecordIO(\n",
    "        os.path.join(rec_path, 'train.idx'),\n",
    "        os.path.join(rec_path, 'train.rec'), 'r')\n",
    "    img_info = imgrec.read_idx(0)\n",
    "    header, _ = mx.recordio.unpack(img_info)\n",
    "    max_idx = int(header.label[0])\n",
    "\n",
    "    file_path = os.path.join(save_path, \"casia-faces\")\n",
    "\n",
    "    if not os.path.isdir(file_path):\n",
    "        os.makedirs(file_path)\n",
    "\n",
    "    data_list = []  # Lista para armazenar dados antes de escrever no CSV\n",
    "\n",
    "    for idx in tqdm(range(1, max_idx), desc=\"Extracting images\"):\n",
    "        img_info = imgrec.read_idx(idx)\n",
    "        header, img = mx.recordio.unpack_img(img_info)\n",
    "        label = int(header.label)\n",
    "        img_path = f\"{label}_{idx}.jpg\"\n",
    "\n",
    "        if write_img and img_path in df['path'].values:\n",
    "            cv2.imwrite(os.path.join(file_path, img_path), img)\n",
    "\n",
    "        data_list.append([img_path, label])\n",
    "\n",
    "    # Criar DataFrame e salvar em CSV\n",
    "    new_df = pd.DataFrame(data_list, columns=['path', 'id'])\n",
    "    new_df.to_csv(os.path.join(save_path, \"casia_faces.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting images: 100%|██████████| 490623/490623 [00:37<00:00, 13168.30it/s]\n"
     ]
    }
   ],
   "source": [
    "load_mx_rec(None, rec_path, output_dir, write_img=False) # Não escrever imagens, apenas obter CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Limpeza**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens no df: 81,280\n",
      "Total de identidades no df: 635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_492547/3328093931.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_clean = df_clean.groupby('id').apply(lambda x: x.sample(128)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Carregar DataFrame\n",
    "df = pd.read_csv(os.path.join(output_dir, 'casia_faces.csv'))\n",
    "\n",
    "# Filtros e seleção de amostras\n",
    "df_clean = df.groupby('id').filter(lambda x: len(x) >= 128)\n",
    "df_clean = df_clean.groupby('id').apply(lambda x: x.sample(128)).reset_index(drop=True)\n",
    "\n",
    "print(f'Total de imagens no df: {df_clean.shape[0]:,}')\n",
    "print(f\"Total de identidades no df: {df_clean['id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting images: 100%|██████████| 490623/490623 [10:43<00:00, 762.95it/s] \n"
     ]
    }
   ],
   "source": [
    "load_mx_rec(df_clean, rec_path, output_dir, write_img=True) # Escreve imagens, somente com amostras selecionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens na pasta: 81,280\n"
     ]
    }
   ],
   "source": [
    "qtd = len(os.listdir(os.path.join(output_dir, 'casia-faces')))\n",
    "print(f'Total de imagens na pasta: {qtd:,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Separar em treino e teste**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecionar 35 identidades para teste\n",
    "test_ids = np.random.choice(df_clean['id'].unique(), 35, replace=False)\n",
    "test_df = df_clean[df_clean['id'].isin(test_ids)]\n",
    "\n",
    "# train_df é o resto\n",
    "train_df = df_clean[~df_clean['id'].isin(test_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df: 76,800 imagens | 600 identidades\n",
      "test_df: 4,480 imagens | 35 identidades\n"
     ]
    }
   ],
   "source": [
    "print(f\"train_df: {train_df.shape[0]:,} imagens | {train_df['id'].nunique()} identidades\")\n",
    "print(f\"test_df: {test_df.shape[0]:,} imagens | {test_df['id'].nunique()} identidades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('./data/CASIA/casia_train.csv', index=False)\n",
    "test_df.to_csv('./data/CASIA/casia_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "facenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
